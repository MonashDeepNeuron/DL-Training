{"cells":[{"cell_type":"markdown","metadata":{"id":"pGTnInyEharX"},"source":["# Before you start\n","1. **Don't edit this file, make a copy first:**\n","  * Click on File -> Save a copy in Drive\n","\n","2. Also do the following:\n","  * Click on Runtime -> Change runtime type -> Make sure hardware accelerator is set to GPU"]},{"cell_type":"markdown","metadata":{"id":"cknZbgNdR6IM"},"source":["# An Overview Before We Begin\n","Here's a couple of important concepts to note down before we start:\n","- There is no one particular methodology that works best in all scenarios. This includes everything from model architecture, learning rate, loss function, and optimizer.\n","- Like any other engineering project, validation of what we have built is just as important as building it."]},{"cell_type":"markdown","metadata":{"id":"ZueWb5ZRDeyT"},"source":["# Library Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DlJ_aMz20rxE"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch import optim\n","from torchvision import datasets, transforms, models\n","\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{"id":"zszDeZ7CJ0Z3"},"source":["# Creating DataLoader\n","- Creating a Dataset. This bundles the data in a way that the model can understand.\n","- Creating a DataLoader(wraps an iterable around the dataset). This tells the model how to receive the images. Including batch_size, num_workers, shuffle configurations, etc."]},{"cell_type":"markdown","metadata":{"id":"R1LivjuALGLi"},"source":["## [Instantiating Transforms](https://https://pytorch.org/docs/stable/torchvision/transforms.html)\n","\n","  - the transforms.Normalize([...]) function basically changes the data slightly according to the average RGB weights in the dataset.\n","  - This may seem a bit strange to you, why do we do this? Turns out, normalizing the data before training results in noticeable performance gains and reduction in training time. Since we generalize the data which makes it easier for the model to train\n","  - So why does normalizing data have such performance boosts in training? That's because by itself, the RGB values of the raw data have differing ranges. the blue pixel may have a range of of 0->125 while the red pixel may have a range of 120->245. This different range often causes headaches for the optimizer and it takes the gradient descent to converge much slowly as it has to cater to the differing conditions of both the red and blue pixel.\n","  - What batch normalization does is that it makes the RGB ranges somewhat similar, so the optimizer doesn't have such a hard time trying to cater for all the different ranges, and thus gradient descent covnerges faster.\n","  - More information here https://medium.com/@urvashilluniya/why-data-normalization-is-necessary-for-machine-learning-models-681b65a05029\n","\n","Now, in the below block of code, come up with a set of tranforms for the training and validation datasets that you think might be suitable. Try using transforms such as rotation, flipping, normalizing, etc.\n","\n","Find the documentation for the transforms here : https://pytorch.org/vision/stable/transforms.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXzCC_fKJzVT"},"outputs":[],"source":["# Define transforms for the training and validation set\n","training_transforms = transforms.Compose([...])           # Convert to tensor\n","\n","validation_transforms = transforms.Compose([...])         #  Convert to tensor"]},{"cell_type":"markdown","metadata":{"id":"qQ9qAGv1LgLC"},"source":["## Download the MNIST Dataset\n","There are a number of ways to create a dataset, for example:\n","- Use an available [Torchvision datasets](https://pytorch.org/docs/stable/torchvision/datasets.html)\n","- Use ImageFolder to create a dataset from folders\n","- Write your own dataset as a subclass of torch.utils.data.Dataset\n","However, for the sake of this workshop, we are going to download the dataset from Tensorflow"]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","# Load MNIST dataset\n","mnist = tf.keras.datasets.mnist\n","\n","# Split the dataset into training and testing sets\n","(x_train, y_train), (x_val, y_val) = mnist.load_data()\n","\n","# Normalize the pixel values to be between 0 and 1\n","x_train, x_val = x_train / 255.0, x_val / 255.0\n"],"metadata":{"id":"beod0LUzdvcK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(x_train))\n","print(x_train.shape, y_train.shape)\n","print(x_val.shape, y_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dE8P70rhd1Wy","executionInfo":{"status":"ok","timestamp":1713790694628,"user_tz":-600,"elapsed":7,"user":{"displayName":"Pham Nguyen","userId":"06242186830021996900"}},"outputId":"7f8ba48c-978d-4c31-d7c7-cb4ce2c17be4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","(60000, 28, 28) (60000,)\n","(10000, 28, 28) (10000,)\n"]}]},{"cell_type":"code","source":["# a quick way to know what are the unique values in the label\n","np.unique(y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_5PA_JtigRu","executionInfo":{"status":"ok","timestamp":1713790694628,"user_tz":-600,"elapsed":6,"user":{"displayName":"Pham Nguyen","userId":"06242186830021996900"}},"outputId":"118273ce-d096-4c6a-a12a-88ff82e548fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## [Instantiating Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n","- Remember to define the ***\\_\\_getitem\\_\\_()*** method and the ***\\_\\_len\\_\\_()*** method"],"metadata":{"id":"pnaKOD7xejaQ"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, data, label, transforms):\n","        self.data = data\n","        self.label = label\n","        self.transforms = transforms\n","\n","    def __getitem__(self, index):\n","        image = ... # get the image based on the index\n","        label = ... # get the label based on the index\n","        image = ... # apply the transformation to the image, but not the label\n","        return image, torch.Tensor(label).int() # the label has to be of type int\n","\n","    def __len__(self):\n","        return ... # return the \"length\" of the data"],"metadata":{"id":"D-yFYpy4fRlF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we need to resize the label to a 2D array so that it can be converted to torch.Tensor\n","training_dataset = CustomDataset(x_train, y_train.reshape(60000, 1), training_transforms)\n","validation_dataset = CustomDataset(x_val, y_val.reshape(10000, 1), validation_transforms)"],"metadata":{"id":"gc29OBNWfgty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run some test for the training_dataset\n","image, label = training_dataset[0]\n","print(np.unique(image), image.shape, label)"],"metadata":{"id":"bB41iAvx7eNZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"njZjCupaUJQN"},"source":["## [Instantiating DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n","- This tells the model *how* how to receive the data; with the dataset as an input, along with batch size and shuffle as args\n","\n","Now code up data loaders for the training and validation datasets as per the followig specs :\n","\n","- In the training_loader, we're telling it batch_size = 32, and we want to shuffle the dataloader after each epoch.\n","- In the validation_loader, we also take batch_size = 32 but we DON'T want to shuffle the dataloader. This is because we want to be testing on the data in the same order to make sure the model really is improving and didn't hit a fluke ordering of the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFxxs8XJULmT"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","training_loader = DataLoader(..., batch_size=..., shuffle=...)\n","validation_loader = DataLoader(..., batch_size=..., shuffle=...)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3NwqQ0DMFlBC"},"source":["# Instantiating our Model\n","It's time to build our own model! Remember:\n","- Inherit the model from the **nn.Module** class\n","- Implement the ***forward()*** method\n","\n","In this section, our model has some specific properties:\n","- The image has to be flattened first\n","- The model has 2 hidden [layers](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html), each has 16 nodes\n","- After each hidden layers, there is a ReLU [activation function](https://pytorch.org/docs/stable/nn.functional.html)\n","- After the last layer, there is a Softmax activation function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXc2SykWNm8J"},"outputs":[],"source":["class DigitRecognition(nn.Module):\n","    def __init__(self):\n","        # initialize a model\n","        super().__init__()\n","        self.flatten_layer = ...\n","        self.linear_layer1 = nn.Linear(..., ..., dtype=torch.float64)\n","        self.linear_layer2 = nn.Linear(..., ..., dtype=torch.float64)\n","        self.last_layer = nn.Linear(..., ..., dtype=torch.float64)\n","    def forward(self, x):\n","\n","        x = self.flatten_layer(x)\n","        x = self.linear_layer1(x)\n","        x = ... # ReLU activation function\n","        x = self.linear_layer2(x)\n","        x = ... # ReLU activation function\n","        x = self.last_layer(x)\n","        x = ... # Softmax activation function\n","        return x\n"]},{"cell_type":"code","source":["model = DigitRecognition()"],"metadata":{"id":"k-I0L-dGlnoz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_jKFQfhkhGf1"},"source":["# The Training Function\n","- The fit() function in Pytorch is used to 'fit' the model and train it\n","<br>\n","<br>\n","\n","Everytime we run through a 'batch' of data we need to do a few things\n","1. Clear the gradients from the previous loop  \n","2. Perform a forward pass (put the input through the model once)\n","3. Calculate the loss\n","4. Back propogate the loss\n","5. Update the parameter weights by taking a step with the optimiser"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwvXsvTnhEKd"},"outputs":[],"source":["# Function for the training\n","\n","def train(model, train_loader, loss_fn, optimizer, device):\n","    model... # puts the model in training mode\n","    running_loss = 0\n","    with tqdm(total=len(train_loader)) as pbar:\n","        for i, data in enumerate(train_loader, 0): # loops through training data\n","            inputs, labels = data # separate inputs and labels (outputs),\n","            inputs, labels = inputs.squeeze(), labels.squeeze().type(torch.LongTensor)\n","            inputs, labels = ..., ... # puts the data on the GPU\n","\n","            # forward + backward + optimize\n","            optimizer... # clear the gradients in model parameters\n","            outputs = ... # forward pass and get predictions, how do we get outputs?\n","\n","            loss = ... # calculate loss, how do we get loss\n","            loss... # calculates gradient w.r.t to loss for all parameters in model that have requires_grad=True\n","            optimizer... # iterate over all parameters in the model with requires_grad=True and update their weights.\n","\n","            running_loss += loss.item() # sum total loss in current epoch for print later\n","\n","            pbar.update(1) #increment our progress bar\n","\n","    return running_loss/len(train_loader) # returns the total training loss for the epoch"]},{"cell_type":"markdown","metadata":{"id":"ZPD3ezm9OZ8t"},"source":["# The Validation Function\n","- A validation function is essential in any model training, because it helps you validate how well your model is performing on the validation dataset.\n","\n","Note: the validation function validates the model performance by passing the entire validation set through the model ONCE. Also note that we cacluate the loss but don't propogate it back or update any weights!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2QY58AvqJDI"},"outputs":[],"source":["# Function for the validation pass\n","\n","def validation(model, val_loader, loss_fn, device):\n","    model... # puts the model in validation mode\n","    running_loss = 0\n","    total = 0\n","    correct = 0\n","\n","    with torch.no_grad(): # save memory by not saving gradients which we don't need\n","        with tqdm(total=len(val_loader)) as pbar:\n","            for inputs, labels in iter(val_loader):\n","                inputs, labels = inputs.squeeze(), labels.squeeze().type(torch.LongTensor)\n","                inputs, labels = ..., ... # put the data on the GPU\n","\n","                outputs = ... # passes image to the model, and gets a ouput which is the class probability prediction\n","                val_loss = ... # calculates val_loss from model predictions and true labels\n","                running_loss += val_loss.item()\n","\n","                _, predicted = torch.max(outputs, 1) # turns class probability predictions to class labels\n","                total += labels.size(0) # sums the number of predictions\n","                correct += (predicted == labels).sum().item() # sums the number of correct predictions\n","\n","                pbar.update(1)\n","\n","        return running_loss/len(val_loader), correct/total # return loss value, accuracy"]},{"cell_type":"markdown","metadata":{"id":"cb8hexwc-8ES"},"source":["#Things to note about our training and validation functions\n","\n","## What's the difference between `model.train()` and `model.eval()`?\n","These two are extremely important to your training and validation loops. `model.eval()` takes away some layers that should only be used during training such as dropout and batch normalisation. It's important to always use `model.train()` when training and `model.eval()` when evaluating.\n","\n","## Why do we need torch.no_grad()?\n","Running `with torch.no_grad()` means that we don't want gradients which is what happens during validation or testing, we don't need to update any gradients so we don't need to record them. Running this means that we optimize our code to not do things it doesn't need to.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jLUTOwwH4-9T"},"source":["# Setting Up Training\n","- When training models, it is substantially faster to train on NVIDIA GPU's, beacuse they offer a parallel computing platform called [cuda](https://developer.nvidia.com/cuda-zone) (cudnn is the API package to interface with cuda) that speeds up these computations exponentially.\n","- So here we check if cuda is available with cuda.is_available().\n","  - Following which, we send the model to the cuda device so the computation can be done on the GPU."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"On6Xdb9TqNOF"},"outputs":[],"source":["%%capture\n","import torch.backends.cudnn as cudnn\n","torch.cuda.empty_cache()\n","cudnn.benchmark = True  # Optimise for hardware\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device) # send model to GPU"]},{"cell_type":"markdown","metadata":{"id":"q4pZVkP5QiwM"},"source":["# Loss Function & Optimizers\n","- The **Loss Function** calculates how 'far' the model's class probability predictions are to the actual labels.\n","  - Notice how I'm saying \"how far the model's class prob predictions are to the actual labels\" instead of \"how innacurate the model is\", that's because accurate/inaccurate is the percentage of correctly or incorrectly predicted labels. This may sound the same to you but just keep this in mind, it will all make sense in due time.\n","  - CrossEntropyLoss is a way of calculating the loss of a model, other loss functions include Kullback Leibler Divergence Loss, Sparse Multiclass Cross-Entropy Loss, and much more.\n","\n","- **The Optimizer** is a way of updating the weights of the model to minimize loss. In other words, the optimizer is the part of deep learning that helps a model 'learn'.\n","- In this case we're using the Adam optimizer, this is purely by random choice as no particular optimizer can be said to be superior to the other. There's an important concept in deep learning called \"no free lunch\", which means there isn't a particular methodology that will achieve the best outcome for all scenarios, what it comes down to is experimentation.\n","  - a lr of 0.001 is also chosen, this is usually a good learning rate start from with the Adam optimizer, however to get a more optimum learning rate, experimentation would need to be done. (The Pytorch documentation includes defaults for each different optimizer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoIZ_7nsqKbt"},"outputs":[],"source":["# choose the suitable loss function and intialize Adam optimizer with learning_rate = 0.001\n","\n","loss_fn = nn.... #what loss function would be good here?\n","optimizer = optim.Adam(..., ...)"]},{"cell_type":"markdown","metadata":{"id":"xedFUaJCMNMR"},"source":["# Let The Training Begin! Part 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":620,"referenced_widgets":["69eeaa431aa04c6899b178e226efcb85","2c3e71f694fb43819c87fcd69504d66a","d7a887cfb06240d9a0e8495d147c217b","41233c379ee945679f27212035999837","14b3463598af4e44a62ddf9b22366fab","fbcde8fd4bad438f8e60fa1e7e506681","1076888299ee4de9bfc42848f7039d6c","15003ff2df1944cd9f802c2487746b5e","0df80b83105446d6b30264bf06abc4bf","f9a073d52429404eae67b8afc33e75a8","ceda2cdbdab8421bbe5000aabc464ebd","f18052e973684daf905d38f6291354d6","fda3197136e24b98aebdf392e9e2dd70","a2d1a531d7f949b3a6e887623ba1ffdb","57d73211737c4c0cabeb52d6f6955a3f","ace47ca9eed44363bc12f603572f225b","2fb3df9a24d04868a7b25ca925b02e78","bfdb6d5f3ffc45f8be304390b8fb1692","363d34bc34d744af913a29acfb45e253","4c174deb2a704797902e4e4c96fd8005","6f15b37eb61a47c6ad309636ac9a58c7","84b747956757471ca9f2612ce6a9f5b8","49fbfbd7922d470fa651c64d23dd8fa7","018dbce090364449929e28698c257f89","0eaaa1df1491492b836dbebad40aefa8","6e19d264934b4961a7b413ddfa26bf3b","cc3426463287464baeadb921fca59650","66ac0b79b3b04f23bcf5a1494ba18eb5","bbe013679dd94ec2b3b6325876d0d28a","186f90cd9db24b70b94fdd5acfd9cc3e","7771c2f425984499a5f3be95b1d5eea2","c6094e96ce72429f860e1ed532e12c2b","738b706925d944c9994d68590ebfee96","da1a3f36124f4c61accec4a33f623079","58751bdd92894303a3827d4e2a81e54f","4dd52bc34fe14c998799abdae4dd6611","a0cecf6d8eeb43aeb5d1233e52eb720f","eefefaff838f473f877186155d0b4e5d","0bd7f29630a44cb69619f2463b280cdd","7f27274dec1e43a59c9214dab29bde56","1b7ae22a17bc4930b7ac600dea41fe2e","860035e1a83a40b1ad411bc815b3467b","6c044a901c2846198303976b63446dec","2f892ffda37d469a94149c5fd6060b7c","2892ea1fab6c4d9db9c3e973d4ee669e","eb1ab760172a459493d0cdeb6cfb5e94","7e221b0d6aa242fdb11ade6195e5e983","12f3b08737104ffeb2d31de3df3c4d35","c354ea15e07a43d2ac1396122c86c937","f602f2ea9c4c4574812882551c2b3ffb","ed67e8c041c44723938b1c049354939c","b53f9e6b65bd47bcb235dbd393561626","dbe4d63ae21745ac862b6ece28a95ece","404370d76af8479e81a97e4f3c88cd9d","482215ca30484ac580375582355daa54"]},"id":"lL8voSz-4fKi","outputId":"592c335d-60d0-4815-dab6-f16e2604b343","executionInfo":{"status":"error","timestamp":1713791009883,"user_tz":-600,"elapsed":16155,"user":{"displayName":"Pham Nguyen","userId":"06242186830021996900"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1875 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69eeaa431aa04c6899b178e226efcb85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/313 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f18052e973684daf905d38f6291354d6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1/5, Training Loss: 1.5875242647723706, Val Loss: 1.5534178475643743, Val Accuracy: 0.9161\n","--------------------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1875 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49fbfbd7922d470fa651c64d23dd8fa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/313 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da1a3f36124f4c61accec4a33f623079"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 2/5, Training Loss: 1.546369159459187, Val Loss: 1.5379025412021257, Val Accuracy: 0.9282\n","--------------------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1875 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2892ea1fab6c4d9db9c3e973d4ee669e"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-063790c8dff3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtotal_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;31m#feel free to play around with how many epochs you guys wanna do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# loops through number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train the model for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# after training for one epoch, run the validation() function to see how the model is doing on the validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {}/{}, Training Loss: {}, Val Loss: {}, Val Accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-74e8cb1216d2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# loops through training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;31m# separate inputs and labels (outputs),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-25f51f7faab0>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the label has to be of type int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["total_epoch = 5 #feel free to play around with how many epochs you guys wanna do\n","for epoch in range(total_epoch): # loops through number of epochs\n","  train_loss = train(model, training_loader, loss_fn, optimizer, device)  # train the model for one epoch\n","  val_loss, accuracy = validation(model, validation_loader, loss_fn, device) # after training for one epoch, run the validation() function to see how the model is doing on the validation dataset\n","  print(\"Epoch: {}/{}, Training Loss: {}, Val Loss: {}, Val Accuracy: {}\".format(epoch+1, total_epoch, train_loss, val_loss, accuracy))\n","  print('-' * 20)\n","\n","print(\"Finished Training\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-J2_a9Gbggo"},"outputs":[],"source":["# We then save the model so we can come back later to it if need be\n","torch.save(model.state_dict(), 'stage-1')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"69eeaa431aa04c6899b178e226efcb85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c3e71f694fb43819c87fcd69504d66a","IPY_MODEL_d7a887cfb06240d9a0e8495d147c217b","IPY_MODEL_41233c379ee945679f27212035999837"],"layout":"IPY_MODEL_14b3463598af4e44a62ddf9b22366fab"}},"2c3e71f694fb43819c87fcd69504d66a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbcde8fd4bad438f8e60fa1e7e506681","placeholder":"​","style":"IPY_MODEL_1076888299ee4de9bfc42848f7039d6c","value":"100%"}},"d7a887cfb06240d9a0e8495d147c217b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15003ff2df1944cd9f802c2487746b5e","max":1875,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0df80b83105446d6b30264bf06abc4bf","value":1875}},"41233c379ee945679f27212035999837":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9a073d52429404eae67b8afc33e75a8","placeholder":"​","style":"IPY_MODEL_ceda2cdbdab8421bbe5000aabc464ebd","value":" 1875/1875 [00:06&lt;00:00, 349.06it/s]"}},"14b3463598af4e44a62ddf9b22366fab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbcde8fd4bad438f8e60fa1e7e506681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1076888299ee4de9bfc42848f7039d6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15003ff2df1944cd9f802c2487746b5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0df80b83105446d6b30264bf06abc4bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9a073d52429404eae67b8afc33e75a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceda2cdbdab8421bbe5000aabc464ebd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f18052e973684daf905d38f6291354d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fda3197136e24b98aebdf392e9e2dd70","IPY_MODEL_a2d1a531d7f949b3a6e887623ba1ffdb","IPY_MODEL_57d73211737c4c0cabeb52d6f6955a3f"],"layout":"IPY_MODEL_ace47ca9eed44363bc12f603572f225b"}},"fda3197136e24b98aebdf392e9e2dd70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb3df9a24d04868a7b25ca925b02e78","placeholder":"​","style":"IPY_MODEL_bfdb6d5f3ffc45f8be304390b8fb1692","value":"100%"}},"a2d1a531d7f949b3a6e887623ba1ffdb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_363d34bc34d744af913a29acfb45e253","max":313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c174deb2a704797902e4e4c96fd8005","value":313}},"57d73211737c4c0cabeb52d6f6955a3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f15b37eb61a47c6ad309636ac9a58c7","placeholder":"​","style":"IPY_MODEL_84b747956757471ca9f2612ce6a9f5b8","value":" 313/313 [00:00&lt;00:00, 648.47it/s]"}},"ace47ca9eed44363bc12f603572f225b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fb3df9a24d04868a7b25ca925b02e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfdb6d5f3ffc45f8be304390b8fb1692":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"363d34bc34d744af913a29acfb45e253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c174deb2a704797902e4e4c96fd8005":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f15b37eb61a47c6ad309636ac9a58c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84b747956757471ca9f2612ce6a9f5b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49fbfbd7922d470fa651c64d23dd8fa7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_018dbce090364449929e28698c257f89","IPY_MODEL_0eaaa1df1491492b836dbebad40aefa8","IPY_MODEL_6e19d264934b4961a7b413ddfa26bf3b"],"layout":"IPY_MODEL_cc3426463287464baeadb921fca59650"}},"018dbce090364449929e28698c257f89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66ac0b79b3b04f23bcf5a1494ba18eb5","placeholder":"​","style":"IPY_MODEL_bbe013679dd94ec2b3b6325876d0d28a","value":"100%"}},"0eaaa1df1491492b836dbebad40aefa8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_186f90cd9db24b70b94fdd5acfd9cc3e","max":1875,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7771c2f425984499a5f3be95b1d5eea2","value":1875}},"6e19d264934b4961a7b413ddfa26bf3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6094e96ce72429f860e1ed532e12c2b","placeholder":"​","style":"IPY_MODEL_738b706925d944c9994d68590ebfee96","value":" 1875/1875 [00:05&lt;00:00, 374.51it/s]"}},"cc3426463287464baeadb921fca59650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ac0b79b3b04f23bcf5a1494ba18eb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe013679dd94ec2b3b6325876d0d28a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"186f90cd9db24b70b94fdd5acfd9cc3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7771c2f425984499a5f3be95b1d5eea2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6094e96ce72429f860e1ed532e12c2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"738b706925d944c9994d68590ebfee96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da1a3f36124f4c61accec4a33f623079":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58751bdd92894303a3827d4e2a81e54f","IPY_MODEL_4dd52bc34fe14c998799abdae4dd6611","IPY_MODEL_a0cecf6d8eeb43aeb5d1233e52eb720f"],"layout":"IPY_MODEL_eefefaff838f473f877186155d0b4e5d"}},"58751bdd92894303a3827d4e2a81e54f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bd7f29630a44cb69619f2463b280cdd","placeholder":"​","style":"IPY_MODEL_7f27274dec1e43a59c9214dab29bde56","value":"100%"}},"4dd52bc34fe14c998799abdae4dd6611":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b7ae22a17bc4930b7ac600dea41fe2e","max":313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_860035e1a83a40b1ad411bc815b3467b","value":313}},"a0cecf6d8eeb43aeb5d1233e52eb720f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c044a901c2846198303976b63446dec","placeholder":"​","style":"IPY_MODEL_2f892ffda37d469a94149c5fd6060b7c","value":" 313/313 [00:00&lt;00:00, 652.88it/s]"}},"eefefaff838f473f877186155d0b4e5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bd7f29630a44cb69619f2463b280cdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f27274dec1e43a59c9214dab29bde56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b7ae22a17bc4930b7ac600dea41fe2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"860035e1a83a40b1ad411bc815b3467b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c044a901c2846198303976b63446dec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f892ffda37d469a94149c5fd6060b7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2892ea1fab6c4d9db9c3e973d4ee669e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb1ab760172a459493d0cdeb6cfb5e94","IPY_MODEL_7e221b0d6aa242fdb11ade6195e5e983","IPY_MODEL_12f3b08737104ffeb2d31de3df3c4d35"],"layout":"IPY_MODEL_c354ea15e07a43d2ac1396122c86c937"}},"eb1ab760172a459493d0cdeb6cfb5e94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f602f2ea9c4c4574812882551c2b3ffb","placeholder":"​","style":"IPY_MODEL_ed67e8c041c44723938b1c049354939c","value":" 57%"}},"7e221b0d6aa242fdb11ade6195e5e983":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_b53f9e6b65bd47bcb235dbd393561626","max":1875,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dbe4d63ae21745ac862b6ece28a95ece","value":1070}},"12f3b08737104ffeb2d31de3df3c4d35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_404370d76af8479e81a97e4f3c88cd9d","placeholder":"​","style":"IPY_MODEL_482215ca30484ac580375582355daa54","value":" 1070/1875 [00:03&lt;00:03, 265.52it/s]"}},"c354ea15e07a43d2ac1396122c86c937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f602f2ea9c4c4574812882551c2b3ffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed67e8c041c44723938b1c049354939c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b53f9e6b65bd47bcb235dbd393561626":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbe4d63ae21745ac862b6ece28a95ece":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"404370d76af8479e81a97e4f3c88cd9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"482215ca30484ac580375582355daa54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}